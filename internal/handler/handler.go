package handler

import (
	"context"
	_ "embed"
	"fmt"
	"io"
	"net/http"
	"strings"
	"time"

	"github.com/eeeming/pip-cache/internal/config"
	"github.com/eeeming/pip-cache/internal/core"
	"github.com/eeeming/pip-cache/internal/proxy"
	"github.com/sirupsen/logrus"
)

//go:embed help.html
var helpPageHTML string

// Handler handles HTTP requests
type Handler struct {
	cache  core.Cache
	proxy  *proxy.ProxyClient
	config *config.Config
	logger *logrus.Logger
}

// NewHandler creates a new HTTP handler
func NewHandler(c core.Cache, p *proxy.ProxyClient, cfg *config.Config, logger *logrus.Logger) *Handler {
	return &Handler{
		cache:  c,
		proxy:  p,
		config: cfg,
		logger: logger,
	}
}

// ServeHTTP implements http.Handler
func (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	requestStart := time.Now()

	// å¤„ç†å¥åº·æ£€æŸ¥
	if r.URL.Path == "/health" {
		h.handleHealth(w, r)
		return
	}

	// å¤„ç†å¸®åŠ©é¡µé¢
	if r.URL.Path == "/" {
		h.handleHelp(w, r)
		return
	}

	// å¤„ç†è·¯å¾„é‡å®šå‘
	if h.handleRedirect(w, r) {
		return
	}

	// åªç¼“å­˜GETè¯·æ±‚
	if r.Method != http.MethodGet {
		h.handleProxy(w, r)
		return
	}

	// ç”Ÿæˆç¼“å­˜key
	cacheKey := core.GenerateKey(r.Method, r.URL.Path)

	// å°è¯•ä»ç¼“å­˜è·å–
	cacheGetStart := time.Now()
	entry, err := h.cache.Get(cacheKey)
	cacheGetDuration := time.Since(cacheGetStart)

	if err != nil {
		h.logger.WithFields(logrus.Fields{
			"cache_key":          cacheKey,
			"cache_get_duration": cacheGetDuration,
			"error":              err.Error(),
		}).Warnf("Cache get error")
	}

	// æ£€æŸ¥ç¼“å­˜å‘½ä¸­ä¸”æœªè¿‡æœŸ
	if entry != nil && !entry.IsExpired() {
		h.logger.WithFields(logrus.Fields{
			"cache_key":          cacheKey,
			"cache_get_duration": cacheGetDuration,
		}).Debugf("âœ… Cache hit")
		h.serveFromCache(w, r, cacheKey)
		h.logger.WithFields(logrus.Fields{
			"cache_key":      cacheKey,
			"total_duration": time.Since(requestStart),
		}).Debugf("ğŸ“¤ Cache hit request completed")
		return
	}

	// ç¼“å­˜æœªå‘½ä¸­ï¼Œä»ä¸Šæ¸¸è·å–å¹¶ç¼“å­˜
	h.logger.WithFields(logrus.Fields{
		"cache_key":          cacheKey,
		"cache_get_duration": cacheGetDuration,
	}).Debugf("âŒ Cache miss")
	h.handleProxyWithCache(w, r, cacheKey)

	h.logger.WithFields(logrus.Fields{
		"cache_key":      cacheKey,
		"total_duration": time.Since(requestStart),
	}).Debugf("ğŸ“¤ Cache miss request completed")
}

// handleHealth handles health check requests
func (h *Handler) handleHealth(w http.ResponseWriter, r *http.Request) {
	cacheSize, _ := h.cache.Size()
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(http.StatusOK)
	fmt.Fprintf(w, `{"status":"healthy","cache_size":%d}`, cacheSize)
}

// handleHelp handles the help page at root path
func (h *Handler) handleHelp(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "text/html; charset=utf-8")
	w.WriteHeader(http.StatusOK)
	fmt.Fprint(w, helpPageHTML)
}

// handleRedirect handles path redirects
func (h *Handler) handleRedirect(w http.ResponseWriter, r *http.Request) bool {
	path := r.URL.Path

	// /simple -> /simple/
	if path == "/simple" {
		http.Redirect(w, r, "/simple/", http.StatusFound)
		return true
	}

	// /simple/package -> /simple/package/
	if strings.HasPrefix(path, "/simple/") && !strings.HasSuffix(path, "/") {
		pathAfterSimple := strings.TrimPrefix(path, "/simple/")
		if pathAfterSimple != "" && !strings.Contains(pathAfterSimple, "/") {
			http.Redirect(w, r, path+"/", http.StatusFound)
			return true
		}
	}

	return false
}

// serveFromCache serves response from cache
func (h *Handler) serveFromCache(w http.ResponseWriter, r *http.Request, cacheKey string) {
	w.Header().Set("X-Cache-Status", "HIT")
	if err := h.cache.StreamFromCache(cacheKey, w); err != nil {
		h.logger.WithFields(logrus.Fields{
			"cache_key": cacheKey,
			"error":     err.Error(),
		}).Warnf("Failed to stream from cache")
		// ç¼“å­˜è¯»å–å¤±è´¥ï¼Œä»ä¸Šæ¸¸è·å–
		h.handleProxyWithCache(w, r, cacheKey)
		return
	}
}

// handleProxyWithCache handles proxying with caching
func (h *Handler) handleProxyWithCache(w http.ResponseWriter, r *http.Request, cacheKey string) {
	// ä»ä¸Šæ¸¸è·å–æµå¼å“åº”
	upstreamStart := time.Now()
	body, headers, statusCode, upstream, err := h.proxy.GetStreamingResponse(r.Method, r.URL.Path, r.Header)
	upstreamDuration := time.Since(upstreamStart)

	if err != nil {
		h.logger.WithFields(logrus.Fields{
			"path":              r.URL.Path,
			"upstream_duration": upstreamDuration,
			"error":             err.Error(),
		}).Errorf("Stream proxy error")
		http.Error(w, "Failed to fetch from upstream", http.StatusBadGateway)
		return
	}
	defer body.Close()

	h.logger.WithFields(logrus.Fields{
		"cache_key":         cacheKey,
		"upstream":          upstream,
		"status_code":       statusCode,
		"upstream_duration": upstreamDuration,
	}).Debugf("âœ… Got streaming response from upstream")

	// åªç¼“å­˜200çŠ¶æ€ç 
	if statusCode != http.StatusOK {
		h.logger.WithFields(logrus.Fields{
			"cache_key":   cacheKey,
			"status_code": statusCode,
		}).Infof("âš ï¸ Not caching: status code %d is not cacheable (only 200 allowed)", statusCode)
		h.streamResponse(w, headers, statusCode, upstream, body, r.Context())
		return
	}

	// æ£€æŸ¥Content-Length
	contentLength, hasLength := proxy.GetContentLength(headers)
	maxCacheSize := int64(float64(h.config.CacheMaxSize) * core.MaxSingleFileRatio)

	// æ£€æŸ¥æ˜¯å¦åº”è¯¥ç¼“å­˜
	shouldCache := !hasLength || contentLength <= maxCacheSize

	// å¯¹äºå¤§æ–‡ä»¶æˆ–ä¸ç¼“å­˜çš„æ–‡ä»¶ï¼Œç›´æ¥æµå¼ä¼ è¾“
	if !shouldCache {
		if !hasLength {
			h.logger.Debugf("Content-Length not available, streaming without cache for %s", cacheKey)
		} else {
			h.logger.Debugf("File too large to cache (%d > %d), streaming without cache for %s",
				contentLength, maxCacheSize, cacheKey)
		}
		// å¯¹äºå·²çŸ¥å¤§å°çš„æ–‡ä»¶ï¼Œä¿ç•™Content-Lengthä»¥æ˜¾ç¤ºè¿›åº¦æ¡
		h.streamResponseWithContentLength(w, headers, statusCode, upstream, body, r.Context(), hasLength, contentLength)
		return
	}

	// å¯¹äºå°æ–‡ä»¶ï¼Œä¸€è¾¹ä»ä¸Šæ¸¸è¯»å–ä¸€è¾¹å‘é€ç»™å®¢æˆ·ç«¯ï¼ŒåŒæ—¶å†™å…¥ç¼“å­˜
	// ç¡®å®šTTL
	ttl := core.GetTTLForPath(r.URL.Path, h.config.SimpleTTL, h.config.PackagesTTL, h.config.DefaultTTL)

	// ä½¿ç”¨StreamToCacheè¿›è¡Œæµå¼ä¼ è¾“ï¼ˆåŒæ—¶å†™å…¥ç¼“å­˜å’Œå®¢æˆ·ç«¯ï¼‰
	// StreamToCacheä¼šä¸€è¾¹ä»ä¸Šæ¸¸è¯»å–ä¸€è¾¹å‘é€ç»™å®¢æˆ·ç«¯ï¼ŒåŒæ—¶å†™å…¥ç¼“å­˜
	// æ³¨æ„ï¼šä¿ç•™Content-Lengthä»¥æ˜¾ç¤ºè¿›åº¦æ¡
	err = h.cache.StreamToCache(cacheKey, body, w, statusCode, headers, ttl, upstream)
	if err != nil {
		h.logger.WithFields(logrus.Fields{
			"cache_key": cacheKey,
			"error":     err.Error(),
		}).Warnf("Failed to cache during streaming, but data was sent to client")
	}
}

// handleProxy handles proxying without caching
func (h *Handler) handleProxy(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	fetchStart := time.Now()

	h.logger.WithFields(logrus.Fields{
		"method": r.Method,
		"path":   r.URL.Path,
	}).Infof("ğŸ”„ Starting proxy fetch")

	done := make(chan struct {
		resp *proxy.ProxyResponse
		err  error
	}, 1)

	go func() {
		resp, err := h.proxy.Fetch(r.Method, r.URL.Path, r.Header)
		done <- struct {
			resp *proxy.ProxyResponse
			err  error
		}{resp, err}
	}()

	select {
	case result := <-done:
		fetchDuration := time.Since(fetchStart)
		if result.err != nil {
			h.logger.WithFields(logrus.Fields{
				"path":           r.URL.Path,
				"fetch_duration": fetchDuration,
				"error":          result.err.Error(),
			}).Errorf("âŒ Proxy fetch error after %v", fetchDuration)
			http.Error(w, "Failed to fetch from upstream", http.StatusBadGateway)
			return
		}

		h.logger.WithFields(logrus.Fields{
			"path":           r.URL.Path,
			"upstream":       result.resp.Upstream,
			"status_code":    result.resp.StatusCode,
			"body_size":      len(result.resp.Body),
			"fetch_duration": fetchDuration,
		}).Infof("âœ… Proxy fetch completed in %v", fetchDuration)

		copyHeaders(w.Header(), result.resp.Headers)
		w.Header().Set("X-Upstream", result.resp.Upstream)
		w.WriteHeader(result.resp.StatusCode)
		w.Write(result.resp.Body)
	case <-ctx.Done():
		fetchDuration := time.Since(fetchStart)
		h.logger.WithFields(logrus.Fields{
			"path":           r.URL.Path,
			"fetch_duration": fetchDuration,
			"error":          ctx.Err().Error(),
		}).Warnf("âš ï¸ Proxy fetch cancelled after %v due to client disconnect", fetchDuration)
		return
	}
}

// streamResponse streams a response to the client using chunked transfer encoding
func (h *Handler) streamResponse(w http.ResponseWriter, headers http.Header, statusCode int, upstream string, body io.ReadCloser, ctx context.Context) {
	h.streamResponseWithContentLength(w, headers, statusCode, upstream, body, ctx, false, 0)
}

// streamResponseWithContentLength streams a response to the client
// If hasLength is true and contentLength > 0, preserves Content-Length header for progress display
func (h *Handler) streamResponseWithContentLength(w http.ResponseWriter, headers http.Header, statusCode int, upstream string, body io.ReadCloser, ctx context.Context, hasLength bool, contentLength int64) {
	// å¤åˆ¶headers
	// å¯¹äºå·²çŸ¥å¤§å°çš„æ–‡ä»¶ï¼Œä¿ç•™Content-Lengthä»¥æ˜¾ç¤ºè¿›åº¦æ¡
	// å¯¹äºæœªçŸ¥å¤§å°çš„æ–‡ä»¶ï¼Œç§»é™¤Content-Lengthä»¥ä½¿ç”¨chunked encoding
	if hasLength && contentLength > 0 {
		// ä¿ç•™Content-Lengthï¼Œä½¿ç”¨æµå¼ä¼ è¾“ä½†æ˜¾ç¤ºè¿›åº¦
		copyHeaders(w.Header(), headers)
	} else {
		// ç§»é™¤Content-Lengthï¼Œä½¿ç”¨chunked encoding
		copyHeadersWithoutContentLength(w.Header(), headers)
	}

	w.Header().Set("X-Cache-Status", "MISS")
	w.Header().Set("X-Upstream", upstream)
	w.WriteHeader(statusCode)

	// ä½¿ç”¨Flusherç¡®ä¿æ•°æ®åŠæ—¶å‘é€
	flusher, hasFlusher := w.(http.Flusher)

	// ç«‹å³flushä¸€æ¬¡ï¼Œè®©å®¢æˆ·ç«¯çŸ¥é“è¿æ¥å·²å»ºç«‹ï¼Œå¯ä»¥å¼€å§‹æ˜¾ç¤ºè¿›åº¦
	if hasFlusher {
		flusher.Flush()
	}

	written, err := copyWithContextChunked(ctx, w, body, hasFlusher, flusher)
	if err != nil && err != context.Canceled {
		h.logger.WithFields(logrus.Fields{
			"written": written,
			"error":   err.Error(),
		}).Warnf("Error copying response body")
	} else if err == context.Canceled {
		h.logger.WithFields(logrus.Fields{
			"written": written,
		}).Debugf("Response copy cancelled (client disconnected)")
	}
}

// copyHeaders copies HTTP headers
func copyHeaders(dst, src http.Header) {
	for key, values := range src {
		for _, value := range values {
			dst.Add(key, value)
		}
	}
}

// copyHeadersWithoutContentLength copies HTTP headers but removes Content-Length
// This allows chunked transfer encoding to be used
func copyHeadersWithoutContentLength(dst, src http.Header) {
	for key, values := range src {
		// è·³è¿‡Content-Lengthï¼Œè®©Goè‡ªåŠ¨ä½¿ç”¨chunked encoding
		if strings.ToLower(key) == "content-length" {
			continue
		}
		// ä¿ç•™Transfer-Encodingå¤´ï¼ˆå¦‚æœä¸Šæ¸¸å·²ç»è®¾ç½®äº†chunkedï¼‰
		for _, value := range values {
			dst.Add(key, value)
		}
	}
}

// copyWithContextChunked copies from src to dst with chunked transfer encoding support
// It flushes data frequently to ensure timely delivery and progress visibility
func copyWithContextChunked(ctx context.Context, dst io.Writer, src io.Reader, hasFlusher bool, flusher http.Flusher) (int64, error) {
	done := make(chan error, 1)
	var written int64
	const chunkSize = 16 * 1024    // 16KB chunks (æ›´å°çš„chunk sizeä»¥æé«˜å“åº”æ€§)
	const flushInterval = 4 * 1024 // Flush every 4KB (éå¸¸é¢‘ç¹çš„flushä»¥æ˜¾ç¤ºè¿›åº¦æ¡)

	go func() {
		buf := make([]byte, chunkSize)
		lastFlushSize := int64(0)

		for {
			select {
			case <-ctx.Done():
				done <- ctx.Err()
				return
			default:
			}

			nr, er := src.Read(buf)
			if nr > 0 {
				nw, ew := dst.Write(buf[0:nr])
				if nw < 0 || nr < nw {
					nw = 0
					if ew == nil {
						ew = fmt.Errorf("invalid write result")
					}
				}
				written += int64(nw)

				// é¢‘ç¹flushä»¥ç¡®ä¿æ•°æ®åŠæ—¶å‘é€ï¼Œè®©å®¢æˆ·ç«¯èƒ½çœ‹åˆ°è¿›åº¦
				// å¯¹äºå¤§æ–‡ä»¶ä¸‹è½½ï¼Œå®¢æˆ·ç«¯éœ€è¦é¢‘ç¹çš„æ›´æ–°æ‰èƒ½æ˜¾ç¤ºè¿›åº¦æ¡
				// æ¯æ¬¡å†™å…¥åæ£€æŸ¥æ˜¯å¦éœ€è¦flushï¼ˆæ¯4KB flushä¸€æ¬¡ï¼‰
				if hasFlusher && written-lastFlushSize >= flushInterval {
					flusher.Flush()
					lastFlushSize = written
				}

				if ew != nil {
					done <- ew
					return
				}
				if nr != nw {
					done <- io.ErrShortWrite
					return
				}
			}
			if er != nil {
				if er != io.EOF {
					done <- er
				} else {
					// æœ€åä¸€æ¬¡flush
					if hasFlusher {
						flusher.Flush()
					}
					done <- nil
				}
				return
			}
		}
	}()

	select {
	case err := <-done:
		return written, err
	case <-ctx.Done():
		return written, ctx.Err()
	}
}
